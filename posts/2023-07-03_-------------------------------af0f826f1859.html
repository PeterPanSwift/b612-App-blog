<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>撰寫爬蟲程式解析包含動態內容的網頁 — 以中華職棒賽程表為例</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">撰寫爬蟲程式解析包含動態內容的網頁 — 以中華職棒賽程表為例</h1>
</header>
<section data-field="subtitle" class="p-summary">
透過分析網站的 html 原始碼，我們可以撰寫爬蟲程式解析網頁的內容。不過有些網站比較麻煩，它們會動態從伺服器加載內容，因此必須用特別的方法才能解析另外加載的內容。
</section>
<section data-field="body" class="e-content">
<section name="8a56" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="66d3" id="66d3" class="graf graf--h3 graf--leading graf--title">撰寫爬蟲程式解析包含動態內容的網頁 — 以中華職棒賽程表為例</h3><p name="2f68" id="2f68" class="graf graf--p graf-after--h3">透過分析網站的 html 原始碼，我們可以撰寫爬蟲程式解析網頁的內容。不過有些網站比較麻煩，它們會動態從伺服器加載內容，因此必須用特別的方法才能解析另外加載的內容。</p><p name="dd29" id="dd29" class="graf graf--p graf-after--p">以下彼得潘以中華職棒的賽程表為例，說明如何撰寫爬蟲程式解析包含動態內容的網頁。</p><ul class="postList"><li name="a2cd" id="a2cd" class="graf graf--li graf-after--p">從 Safari 將網頁存成 webarchive 格式。</li><li name="1bb9" id="1bb9" class="graf graf--li graf-after--li">從 web archive 生成 html。</li><li name="fdb5" id="fdb5" class="graf graf--li graf-after--li">請 AI 寫 python 爬蟲程式解析 html。</li><li name="2c1e" id="2c1e" class="graf graf--li graf-after--li">執行 python 程式產生 JSON。</li></ul><h3 name="5e16" id="5e16" class="graf graf--h3 graf-after--li">連到中華職棒的賽程表頁面</h3><div name="71ec" id="71ec" class="graf graf--mixtapeEmbed graf-after--h3"><a href="https://www.cpbl.com.tw/schedule" data-href="https://www.cpbl.com.tw/schedule" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://www.cpbl.com.tw/schedule"><strong class="markup--strong markup--mixtapeEmbed-strong">中華職棒大聯盟全球資訊網 The Official Site of CPBL</strong><br><em class="markup--em markup--mixtapeEmbed-em">中華職業棒球大聯盟（CPBL），簡稱中華職棒、中職，是臺灣目前唯一的職業棒球聯盟，也是臺灣最早成立的職業運動聯盟。</em>www.cpbl.com.tw</a><a href="https://www.cpbl.com.tw/schedule" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="84a27621bd9f3e0d053b0ca3af292001" data-thumbnail-img-id="0*7vZ1X5_HTFNwIGSr" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*7vZ1X5_HTFNwIGSr);"></a></div><p name="1eb4" id="1eb4" class="graf graf--p graf-after--mixtapeEmbed">切換成列表顯示，因為我們要儲存賽程的 table。</p><figure name="10ea" id="10ea" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*5ugoZmcsR0DMkBWKocPWbw.png" data-width="1962" data-height="1392" src="https://cdn-images-1.medium.com/max/800/1*5ugoZmcsR0DMkBWKocPWbw.png"></figure><h3 name="5831" id="5831" class="graf graf--h3 graf-after--figure">從 Safari 將網頁存成 web archive 格式</h3><p name="13ee" id="13ee" class="graf graf--p graf-after--h3">點選 Safari menu 的 File &gt; Save As。</p><figure name="2dba" id="2dba" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*iGJJmlDykgkNVb0RuIomRQ.png" data-width="680" data-height="640" src="https://cdn-images-1.medium.com/max/800/1*iGJJmlDykgkNVb0RuIomRQ.png"></figure><p name="f809" id="f809" class="graf graf--p graf-after--figure">Format 選擇 Web Archive。</p><figure name="dbfa" id="dbfa" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*ks6haqGndyVFsqrrPL6YzQ.png" data-width="1590" data-height="890" src="https://cdn-images-1.medium.com/max/800/1*ks6haqGndyVFsqrrPL6YzQ.png"></figure><h3 name="515d" id="515d" class="graf graf--h3 graf-after--figure">從 web archive 生成 html</h3><p name="ae30" id="ae30" class="graf graf--p graf-after--h3">打開 terminal，切換到 web archive 檔的路徑下，輸入以下指令將 web archive 的內容輸出成 html</p><pre data-code-block-mode="0" spellcheck="false" name="e7c0" id="e7c0" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">textutil -convert html cpbl.webarchive </span></pre><p name="0983" id="0983" class="graf graf--p graf-after--pre">生成的 html 內容如下，完整包含八月份的賽程資料，下圖選取的區塊是 8/1 的比賽資訊。</p><figure name="f1b2" id="f1b2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*JsXqhU6Xq-Aoqc0AXqOO7w.png" data-width="2458" data-height="1208" src="https://cdn-images-1.medium.com/max/800/1*JsXqhU6Xq-Aoqc0AXqOO7w.png"></figure><figure name="2f7e" id="2f7e" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*ec_6d6ES32phZO8pWc4tew.png" data-width="1096" data-height="144" src="https://cdn-images-1.medium.com/max/800/1*ec_6d6ES32phZO8pWc4tew.png"></figure><h3 name="dbf6" id="dbf6" class="graf graf--h3 graf-after--figure">請 AI 寫 python 爬蟲程式解析 html</h3><p name="3d5e" id="3d5e" class="graf graf--p graf-after--h3">詢問 GPT 4 的 prompt 有字數限制，因此我們不能貼上全部的 html。彼得潘在 prompt 貼上某一天賽程的 html 和想要的 JSON 格式，請 GPT 4 研究 html 撰寫爬蟲程式。</p><div name="75d8" id="75d8" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://chat.openai.com/share/082feb05-f9c2-4e11-8d8c-60abc0aedcd5" data-href="https://chat.openai.com/share/082feb05-f9c2-4e11-8d8c-60abc0aedcd5" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://chat.openai.com/share/082feb05-f9c2-4e11-8d8c-60abc0aedcd5"><strong class="markup--strong markup--mixtapeEmbed-strong">解析 HTML 賽程</strong><br><em class="markup--em markup--mixtapeEmbed-em">A conversational AI system that listens, learns, and challenges</em>chat.openai.com</a><a href="https://chat.openai.com/share/082feb05-f9c2-4e11-8d8c-60abc0aedcd5" class="js-mixtapeImage mixtapeImage mixtapeImage--empty u-ignoreBlock" data-media-id="f162880448420988b45b1ebffc3dde9c"></a></div><figure name="3b7d" id="3b7d" class="graf graf--figure graf-after--mixtapeEmbed"><img class="graf-image" data-image-id="1*vCrFfM0BToe7l17CyCyECg.png" data-width="1092" data-height="1392" src="https://cdn-images-1.medium.com/max/800/1*vCrFfM0BToe7l17CyCyECg.png"></figure><p name="7ec1" id="7ec1" class="graf graf--p graf-after--figure">產生的爬蟲程式如下。</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="3d13" id="3d13" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">import</span> json<br /><span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup<br /><br /><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_html</span>(<span class="hljs-params">filename</span>):<br />    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br />        content = f.read()<br /><br />    soup = BeautifulSoup(content, <span class="hljs-string">&#x27;html.parser&#x27;</span>)<br /><br />    games = []<br />    game = {}<br /><br />    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> soup.find_all(<span class="hljs-string">&#x27;p&#x27;</span>):<br />        <span class="hljs-comment"># 獲取日期</span><br />        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;p28&#x27;</span> <span class="hljs-keyword">in</span> p.get(<span class="hljs-string">&#x27;class&#x27;</span>, []):<br />            date = p.get_text(strip=<span class="hljs-literal">True</span>)<br />        <span class="hljs-comment"># 獲取隊伍資訊</span><br />        <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;p31&#x27;</span> <span class="hljs-keyword">in</span> p.get(<span class="hljs-string">&#x27;class&#x27;</span>, []):<br />            teams = p.find_all(<span class="hljs-string">&#x27;a&#x27;</span>)<br />            game[<span class="hljs-string">&#x27;teams&#x27;</span>] = {<br />                <span class="hljs-string">&#x27;away&#x27;</span>: teams[<span class="hljs-number">0</span>].get_text(strip=<span class="hljs-literal">True</span>),<br />                <span class="hljs-string">&#x27;home&#x27;</span>: teams[<span class="hljs-number">1</span>].get_text(strip=<span class="hljs-literal">True</span>)<br />            }<br />        <span class="hljs-comment"># 獲取場地</span><br />        <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;p32&#x27;</span> <span class="hljs-keyword">in</span> p.get(<span class="hljs-string">&#x27;class&#x27;</span>, []):<br />            game[<span class="hljs-string">&#x27;venue&#x27;</span>] = p.get_text(strip=<span class="hljs-literal">True</span>)<br />        <span class="hljs-comment"># 獲取時間</span><br />        <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;p33&#x27;</span> <span class="hljs-keyword">in</span> p.get(<span class="hljs-string">&#x27;class&#x27;</span>, []):<br />            game[<span class="hljs-string">&#x27;time&#x27;</span>] = p.get_text(strip=<span class="hljs-literal">True</span>)<br />            game[<span class="hljs-string">&#x27;date&#x27;</span>] = date<br />            games.append(game)<br />            game = {}<br />    <span class="hljs-keyword">return</span> games<br /><br /><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br />    games = parse_html(<span class="hljs-string">&#x27;cpbl.html&#x27;</span>)<br /><br />    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;games.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br />        json.dump(games, f, ensure_ascii=<span class="hljs-literal">False</span>, indent=<span class="hljs-number">4</span>)<br /><br /><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br />    main()</span></pre><h3 name="df24" id="df24" class="graf graf--h3 graf-after--pre">執行 python 程式產生 JSON</h3><p name="9631" id="9631" class="graf graf--p graf-after--h3">順利生成中華職棒 2023/8 賽程的 JSON 檔，包含了日期，時間，球隊和地點。</p><figure name="13c7" id="13c7" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*2b73qrMuQH-IOTMtafZzAQ.png" data-width="846" data-height="1404" src="https://cdn-images-1.medium.com/max/800/1*2b73qrMuQH-IOTMtafZzAQ.png"></figure><figure name="c038" id="c038" class="graf graf--figure graf-after--figure graf--trailing"><img class="graf-image" data-image-id="1*MABmVF5ZKAQtMXBGExkraA.png" data-width="762" data-height="1296" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*MABmVF5ZKAQtMXBGExkraA.png"></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@apppeterpan" class="p-author h-card">彼得潘的 iOS App Neverland</a> on <a href="https://medium.com/p/af0f826f1859"><time class="dt-published" datetime="2023-07-03T14:44:22.826Z">July 3, 2023</time></a>.</p><p><a href="https://medium.com/@apppeterpan/%E6%92%B0%E5%AF%AB%E7%88%AC%E8%9F%B2%E7%A8%8B%E5%BC%8F%E8%A7%A3%E6%9E%90%E5%8C%85%E5%90%AB%E5%8B%95%E6%85%8B%E5%85%A7%E5%AE%B9%E7%9A%84%E7%B6%B2%E9%A0%81-%E4%BB%A5%E4%B8%AD%E8%8F%AF%E8%81%B7%E6%A3%92%E8%B3%BD%E7%A8%8B%E8%A1%A8%E7%82%BA%E4%BE%8B-af0f826f1859" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on November 16, 2025.</p></footer></article></body></html>